{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9274ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Libraries\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import glob, os, re, time, sys, math, ast, json\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from numpy import savetxt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\n",
    "#from tensorflow.keras.preprocessing.image import save_img\n",
    "#from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import glob, os, re, time, sys, math, ast, json\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from numpy import savetxt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img\n",
    "\n",
    "print('Importing Libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae21daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalog_to_dataframe(line_list):\n",
    "    res = [ast.literal_eval(x) for x in line_list] \n",
    "    dataframe = pd.DataFrame(res)\n",
    "    dataframe = dataframe.set_index('_index')\n",
    "    dataframe = dataframe.drop(['_session_id','_timestamp_ms', 'user/mode'], axis = 1)\n",
    "    return dataframe\n",
    "\n",
    "def numericalSort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def make_dataframe(main_dir):\n",
    "    catalog_files=sorted(glob.glob(main_dir), key=numericalSort)\n",
    "    myDataFrame = pd.DataFrame()\n",
    "    for i in range (0, len(catalog_files)):\n",
    "        infile = open(catalog_files[i]) \n",
    "        lines = infile.readlines()\n",
    "        df = catalog_to_dataframe(lines)\n",
    "        myDataFrame = myDataFrame.append(df)\n",
    "    return myDataFrame\n",
    "\n",
    "def steeing_throttle(n1, n2, n3, n4, s_t, f):\n",
    "    n=np.concatenate((n1, n2, n3, n4),axis=0)\n",
    "    nn = n.tolist()\n",
    "    rounded_nn = [ '%.6f' % i for i in nn ]\n",
    "    if s_t=='s':\n",
    "        with open('steering_{}.json'.format(f), 'w', encoding='utf-8') as f:  # saving steering value as json file\n",
    "            json.dump(nn, f, ensure_ascii=False, indent=4)\n",
    "    if s_t=='t':\n",
    "        with open('throttle_{}.json'.format(f), 'w', encoding='utf-8') as f:  # saving throttle value as json file\n",
    "            json.dump(nn, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        pass\n",
    "    return rounded_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22aa1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir_1=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/first/*.catalog'\n",
    "main_dir_2=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/second/*.catalog'\n",
    "df_1 = make_dataframe(main_dir_1)\n",
    "df_2 = make_dataframe(main_dir_2)\n",
    "\n",
    "#Steering column from dataframe\n",
    "column_s1 = df_1.loc[100:20472,'user/angle']\n",
    "arr_s1 = column_s1.values\n",
    "column_s2 = df_2.loc[:,'user/angle']\n",
    "arr_s2 = column_s2.values\n",
    "\n",
    "#Throttle column from dataframe\n",
    "column_t1 = df_1.loc[100:20472,'user/throttle']\n",
    "arr_t1 = column_t1.values\n",
    "column_t2 = df_2.loc[:,'user/throttle']\n",
    "arr_t2 = column_t2.values\n",
    "\n",
    "dir_new_1=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/new_data_1/*.catalog'\n",
    "dir_new_2=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/new_data_2/*.catalog'\n",
    "df_new_1 = make_dataframe(dir_new_1)\n",
    "df_new_2 = make_dataframe(dir_new_2)\n",
    "\n",
    "#Steering column from dataframe\n",
    "column_new_s1 = df_new_1.loc[217:,'user/angle']\n",
    "arr_new_s1 = column_new_s1.values\n",
    "column_new_s2 = df_new_2.loc[:15433,'user/angle']\n",
    "arr_new_s2 = column_new_s2.values\n",
    "\n",
    "#Throttle column from dataframe\n",
    "column_new_t1 = df_new_1.loc[217:,'user/throttle']\n",
    "arr_new_t1 = column_new_s1.values\n",
    "column_new_t2 = df_new_2.loc[:15433,'user/throttle']\n",
    "arr_new_t2 = column_new_t2.values\n",
    "\n",
    "\n",
    "# steering_list_1=steeing_throttle(arr_s1, arr_s2, s_t='s', f=1) \n",
    "# throttle_list_1=steeing_throttle(arr_t1, arr_t2, s_t='t', f=1)\n",
    "\n",
    "# steering_list_2=steeing_throttle(arr_new_s1, arr_new_s2, s_t='s', f=2) \n",
    "# throttle_list_2=steeing_throttle(arr_new_t1, arr_new_t2, s_t='t', f=2)\n",
    "\n",
    "steering_list_new=steeing_throttle(arr_s1, arr_s2, arr_new_s1, arr_new_s2, s_t='s', f='new') \n",
    "throttle_list_new=steeing_throttle(arr_t1, arr_t2, arr_new_t1, arr_new_t2, s_t='t', f='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d4f3173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20373, 53426, 40890, 15434, 130123, 130123)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr_s1), len(arr_s2), len(arr_new_s1), len(arr_new_s2), len(steering_list_new), len(throttle_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bc6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir1=\"C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/first/*.jpg\"\n",
    "img_dir2=\"C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/second/*.jpg\"\n",
    "files_1=sorted(glob.glob(img_dir1), key=numericalSort)\n",
    "files_2=sorted(glob.glob(img_dir2), key=numericalSort)\n",
    "\n",
    "img_dir_new_1='C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/new_data_1/*.jpg'\n",
    "img_dir_new_2='C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/new_data_2/*.jpg'\n",
    "files_new_1=sorted(glob.glob(img_dir_new_1), key=numericalSort)\n",
    "files_new_2=sorted(glob.glob(img_dir_new_2), key=numericalSort)\n",
    "\n",
    "order_new = [files_1[100:20473], files_2, files_new_1[217:], files_new_2[:15434]]\n",
    "#order_new = [files_new_1, files_new_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684c2810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20373, 53426, 40890, 15434)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_new[0]), len(order_new[1]), len(order_new[2]), len(order_new[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ded68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "for i in range(0,len(order_new)):\n",
    "    for j in order_new[i]:\n",
    "        # print(j)\n",
    "        img=cv2.imread(j)\n",
    "        #cv2.imshow('sample image',img)\n",
    "        #cv2.waitKey(0) # waits until a key is pressed\n",
    "        #cv2.destroyAllWindows()\n",
    "        m+=1\n",
    "        cv2.imwrite('C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/lane/cv/full/{}.jpg'.format(m), img) #create new folder to save each time to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709b9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91dd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b5dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435abda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201855a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34239429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7201ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdbbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir_1=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/first/*.catalog'\n",
    "main_dir_2=r'C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/second/*.catalog'\n",
    "#main_dir_3=r'C:/Users/Nishanth Siegener/Downloads/Bumblebee/Data/five/*.catalog'\n",
    "df_1 = make_dataframe(main_dir_1)\n",
    "df_2 = make_dataframe(main_dir_2)\n",
    "\n",
    "#Steering column from dataframe\n",
    "column_s1 = df_1.loc[100:20472,'user/angle']\n",
    "arr_s1 = column_s1.values\n",
    "\n",
    "column_s2 = df_2.loc[:,'user/angle']\n",
    "arr_s2 = column_s2.values\n",
    "\n",
    "#Throttle column from dataframe\n",
    "column_t1 = df_1.loc[100:20472,'user/throttle']\n",
    "arr_t1 = column_t1.values\n",
    "\n",
    "column_t2 = df_2.loc[:,'user/throttle']\n",
    "arr_t2 = column_t2.values\n",
    "\n",
    "\n",
    "#steering_list=steeing_throttle(arr_s1, arr_s2, s_t='s') \n",
    "#throttle_list=steeing_throttle(arr_t1, arr_t2, s_t='t')\n",
    "#r_start=60\n",
    "#r_end=63\n",
    "#myDF=myDataFrame.iloc[r_start:-r_end]\n",
    "#myDF=myDataFrame[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52166965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20373"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr_s1)#, len(steering_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c84228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir1=\"C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/first/*.jpg\"\n",
    "img_dir2=\"C:/Users/Nishanth Siegener/Downloads/Studienarbeit/Bumblebee/Data/second/*.jpg\"\n",
    "\n",
    "files_1=sorted(glob.glob(img_dir1), key=numericalSort)\n",
    "files_2=sorted(glob.glob(img_dir2), key=numericalSort)\n",
    "\n",
    "row_start=100\n",
    "row_end=-63\n",
    "order = [files_1[100:20473], files_2]\n",
    "# order = files_1[r_start:r_end] + files_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa595329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fe00c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20470,20474):                                  \n",
    "    img=cv2.imread(files_1[i])\n",
    "    cv2.imshow('sample image',img)\n",
    "    cv2.waitKey(0) # waits until a key is pressed\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7334c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load and save the images using OpenCV\n",
    "\n",
    "m=0\n",
    "for i in range(0,len(order)):\n",
    "    for j in order[i]:\n",
    "        # print(j)\n",
    "        img=cv2.imread(j)\n",
    "        #cv2.imshow('sample image',ima)\n",
    "        #cv2.waitKey(0) # waits until a key is pressed\n",
    "        #cv2.destroyAllWindows()\n",
    "        m+=1\n",
    "        cv2.imwrite('C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/lane/cv/2/{}.jpg'.format(m), img) # create new folder to save each time to avoid confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18016776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\n# Load and save using Tensorflow\\n\\nimm=[]\\nn=0\\nfor i in range(0,len(order)):\\n    for j in order[i]:\\n        imagess=load_img(j,grayscale=False, color_mode='rgb',target_size= (120,160))\\n        \\n        # convert image to a numpy array\\n        img_array = img_to_array(imagess)\\n        imm.append(img_array)\\n        \\n        # save the image with a new filename\\n        n+=1\\n        save_img('C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/lane/tf/2/{}.jpg'.format(n), img_array) # better to create new folder to save each time to avoid confusion\\n# images_array=np.array(imm)\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "# Load and save using Tensorflow\n",
    "\n",
    "imm=[]\n",
    "n=0\n",
    "for i in range(0,len(order)):\n",
    "    for j in order[i]:\n",
    "        imagess=load_img(j,grayscale=False, color_mode='rgb',target_size= (120,160))\n",
    "        \n",
    "        # convert image to a numpy array\n",
    "        img_array = img_to_array(imagess)\n",
    "        imm.append(img_array)\n",
    "        \n",
    "        # save the image with a new filename\n",
    "        n+=1\n",
    "        save_img('C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/lane/tf/2/{}.jpg'.format(n), img_array) # better to create new folder to save each time to avoid confusion\n",
    "# images_array=np.array(imm)'''\n",
    "#np.save('images_array', images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4178264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a4045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89194a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-531cb3be9a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mimg_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_images_from_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/fm/forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-531cb3be9a0c>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[1;34m(foldername)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumericalSort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(foldername):\n",
    "    images = []\n",
    "    for filename in os.listdir(foldername):\n",
    "        files=sorted(glob.glob(filename), key=numericalSort)\n",
    "        print(files)\n",
    "        img = cv2.imread(os.path.join(foldername,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "img_list=load_images_from_folder(\"C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/fm/forest\")\n",
    "img_array=np.array(img_list, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b7aa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b1fda49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/111.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/114.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/115.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/23.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/41.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/46.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/48.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/49.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/8.jpg\n",
      "C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/98.jpg\n"
     ]
    }
   ],
   "source": [
    "foldername=\"C:/Users/Nishanth Siegener/Documents/GitHub/dummy_data_nis/forest/\"\n",
    "im=os.listdir(foldername)\n",
    "for filename in im:\n",
    "    print(os.path.join(foldername,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11d30c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sample image',img_array[0])\n",
    " \n",
    "cv2.waitKey(0) # waits until a key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99113c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad66aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (first_layer): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (second_layer): Sequential(\n",
      "    (0): Conv2d(24, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (third_layer): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fourth_layer): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (fifth_layer): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2, inplace=False)\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fcx1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fcy1): Linear(in_features=6, out_features=14, bias=True)\n",
      "  (fcy2): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (fcy3): Linear(in_features=14, out_features=14, bias=True)\n",
      "  (fcz1): Linear(in_features=114, out_features=50, bias=True)\n",
      "  (fcz2): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (fcz3): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel           input_shape=(480, 620, 3) 480/2/2/2/2/2 after max pooling, 620/2/2/2/2/2\n",
    "\n",
    "        # CNN #input Channel,output channel,size of the kernel,stride,padding\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 24, 5, stride=1, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(24, 32, 5, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                          nn.Dropout2d(p=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, 5, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                          nn.Dropout2d(p=0.2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "\n",
    "        # pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fcx1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        # self.fcx2 = nn.Linear(120, 84)\n",
    "        # self.fcx3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.fcy1 = nn.Linear(6, 14)\n",
    "        self.fcy2 = nn.Linear(14, 14)\n",
    "        self.fcy3 = nn.Linear(14, 14)\n",
    "\n",
    "        self.fcz1 = nn.Linear(114, 50)\n",
    "        self.fcz2 = nn.Linear(50, 20)\n",
    "        self.fcz3 = nn.Linear(20, 2)\n",
    "\n",
    "    # noinspection PyUnusedLocal\n",
    "    def forward(self, x, y):\n",
    "        x = self.pool(self.first_layer)\n",
    "        x = self.pool(self.second_layer)\n",
    "        x = self.pool(self.third_layer)\n",
    "        x = self.pool(self.fourth_layer)\n",
    "        x = self.pool(self.fifth_layer)\n",
    "        # x = x.view(-1, 64 * 15 * 19) #19 or 20 not sure dimension of the image\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension  nn.Dropout(0.2)\n",
    "        x = F.relu(self.fcx1(x))\n",
    "        # x = F.relu(self.fcx2(x))\n",
    "        # x = F.relu(self.fcx3(x))\n",
    "        y = F.relu(self.fcy1(y))\n",
    "        y = F.relu(self.fcy2(y))\n",
    "        y = F.relu(self.fcy3(y))\n",
    "        z = torch.cat((x, y), dim=1)\n",
    "        z = F.relu(self.fcz1(y))\n",
    "        z = F.relu(self.fcz2(y))\n",
    "        z = F.relu(self.fcz3(y))\n",
    "        return z\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f5648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm2d(100)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66974722",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-61353e8b2d5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354b228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652345af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b69e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec39a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4771df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e7ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b90ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5a9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ba619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from keras import Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D\n",
    "from keras.models import Model\n",
    "from numpy import concatenate\n",
    "from tensorflow.keras.backend import concatenate\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "def conv2d(filters, kernel, strides, layer_num, activation='relu'):\n",
    "    return Convolution2D(filters=filters,\n",
    "                         kernel_size=(kernel, kernel),\n",
    "                         strides=(strides, strides),\n",
    "                         activation=activation,\n",
    "                         name='conv2d_' + str(layer_num))\n",
    "\n",
    "\n",
    "def core_cnn_layers(img_in, drop, l4_stride=1):\n",
    "    img_in = tf.cast(img_in, dtype=tf.float32)\n",
    "    x = img_in\n",
    "    x = conv2d(24, 5, 2, 1)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = conv2d(32, 5, 2, 2)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = conv2d(64, 5, 2, 3)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = conv2d(64, 3, l4_stride, 4)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = conv2d(64, 3, 1, 5)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = Flatten(name='flattened')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def default_imu(num_outputs, imu_in, num_imu_inputs, img_in, input_shape):\n",
    "    drop = 0.2\n",
    "    im = Input(shape=input_shape, name='img_in')\n",
    "    imu = Input(shape=num_imu_inputs, name=\"imu_in\")\n",
    "\n",
    "    x = core_cnn_layers(img_in, drop)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "\n",
    "    y = imu_in\n",
    "    y = Dense(14, activation='relu')(y)\n",
    "    y = Dense(14, activation='relu')(y)\n",
    "    y = Dense(14, activation='relu')(y)\n",
    "\n",
    "    z = concatenate([x, y])\n",
    "    z = Dense(50, activation='relu')(z)\n",
    "    z = Dropout(.1)(z)\n",
    "    z = Dense(50, activation='relu')(z)\n",
    "    z = Dropout(.1)(z)\n",
    "    z = Dense(20, activation='relu')(z)\n",
    "    z = Dropout(.1)(z)\n",
    "    outputs = [Dense(1, activation='linear', name='out_' + str(i))(z) for i in range(num_outputs)]\n",
    "\n",
    "    outputs = tf.convert_to_tensor(outputs, dtype=None, dtype_hint=None, name=None)\n",
    "    # tf.convert_to_tensor(value, dtype=None, dtype_hint=None, name=None)\n",
    "    print(outputs)\n",
    "    model = Model(inputs=[im, imu], outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel           input_shape=(480, 620, 3) 480/2/2/2/2/2 after max pooling, 620/2/2/2/2/2\n",
    "\n",
    "        # CNN #input Channel,output channel,size of the kernel,padding\n",
    "        self.first_layer = nn.Sequential(nn.Conv2d(3, 24, 5, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "        self.second_layer = nn.Sequential(nn.Conv2d(24, 32, 5, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                          nn.Dropout2d(p=0.2))\n",
    "        self.third_layer = nn.Sequential(nn.Conv2d(32, 64, 5, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "        self.fourth_layer = nn.Sequential(nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                          nn.Dropout2d(p=0.2))\n",
    "        self.fifth_layer = nn.Sequential(nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                         nn.Dropout2d(p=0.2))\n",
    "\n",
    "        # pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fcx1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        # self.fcx2 = nn.Linear(120, 84)\n",
    "        # self.fcx3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.fcy1 = nn.Linear(6, 14)\n",
    "        self.fcy2 = nn.Linear(14, 14)\n",
    "        self.fcy3 = nn.Linear(14, 14)\n",
    "\n",
    "        self.fcz1 = nn.Linear(114, 50)\n",
    "        self.fcz2 = nn.Linear(50, 20)\n",
    "        self.fcz3 = nn.Linear(20, 2)\n",
    "\n",
    "    # noinspection PyUnusedLocal\n",
    "    def forward(self, x, y):\n",
    "        x = self.pool(self.first_layer)\n",
    "        x = self.pool(self.second_layer)\n",
    "        x = self.pool(self.third_layer)\n",
    "        x = self.pool(self.fourth_layer)\n",
    "        x = self.pool(self.fifth_layer)\n",
    "        # x = x.view(-1, 64 * 15 * 19) #19 or 20 not sure dimension of the image\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension  nn.Dropout(0.2)\n",
    "        x = F.relu(self.fcx1(x))\n",
    "        # x = F.relu(self.fcx2(x))\n",
    "        # x = F.relu(self.fcx3(x))\n",
    "        y = F.relu(self.fcy1(y))\n",
    "        y = F.relu(self.fcy2(y))\n",
    "        y = F.relu(self.fcy3(y))\n",
    "        z = torch.cat((x, y), dim=1)\n",
    "        z = F.relu(self.fcz1(y))\n",
    "        z = F.relu(self.fcz2(y))\n",
    "        z = F.relu(self.fcz3(y))\n",
    "        return z\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
